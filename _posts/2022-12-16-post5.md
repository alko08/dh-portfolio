---
layout: post
title:  "The Collaborative Musical Text"
date:   "2022-12-16"
---
“The Collaborative Musical Text” by Richard Freedman

This article by Richard Freedman is a lot. I have read it through multiple times and honestly, the article confuses me. It seems like Richard Freedman’s main takeaway is that the world is constantly changing and that humanities and how things are done, like research or education, are also constantly changing and need to adapt to the digital revolution. New standards need to be set in place and new ways of handling data need to be established as the old standard we used for handling data like text does not work when handling more complicated pieces like music.

While I agree with and understand what Richard Freedman is trying to get at, the article fails to fully communicate that with me, but we can move past that. For one, the article brings up many good points. One of the most recurring points is that not all data is equal, and when looking at data like music there is a lot of important metadata attached. How will we keep track of who performed the music, who edited the music, and who wrote the music all inside the metadata? It is a good question that neither I nor Richard has the answer to. I never thought about how much metadata there could be attached to a sound clip before, but they are completely right, how do we keep track of all this data? I think most modern solutions just write the information on the same page/site the audio recording can be found, but that means that if the audio got shared, the metadata likely would not be shared along with it. 

Another point Richard Freedman brings up, which seems a little off-topic, is the idea of “users first, platform second” (6) which is an idea I totally agree with, but one that does not make much sense. Yes, any app, music producer, or even researcher should care about the audience they are selling or talking to above all else, but what does that have to do with metadata and how do we need to adapt our use of technology? Maybe Richard Freedman is saying that our job as developers is to make sure the users understand these ideas above all else. This makes the most sense to me, as I agree if we could attach the metadata of the audio recording better the sound clip as a developer, and the users would understand its importance more.

While I find it hard to fully grasp Richard Freedman’s meaning, the article does bring up many interesting points of discussion. The most interesting one to me is the idea of metadata.