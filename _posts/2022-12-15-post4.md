---
layout: post
title:  "Topic Modeling"
date:   "2022-12-15"
---
“Topic Modeling and Digital Humanities” by David M. Blei

As defined by the article, topic modeling involves the use of algorithms to find “hidden thematic structure in large collections of texts” (paragraph 1). This means that, in some sense, a computer can actually analyze text and figure out what the text is talking about, without even knowing what all the words actually mean. Topic modeling does this by analyzing the text and finding patterns of tightly clustered words that often appear together. For example, it might read that “pet”, “dog”, “food”, and “water” occur a lot together and define it as a topic that a researcher could later define as “taking care of a dog”. This is an amazing tool as it has many different uses, from summarizing large amounts of text to visualizing and exploring text in a way previously not done before. The first example David Blei gives is an illustration created by a topic model that was fed 1.8 million articles from the New York Times. This tool gave the researchers a framework to explore and analyze the New York Times by giving a list of topics included in the articles, and the researchers did not have to define any of the topics themselves (2).

I find topic modeling as a whole to be an amazing tool. It would take a team of people many days, months, and maybe even years to sort 1.8 million articles by category, but a computer can do it in seconds without even knowing what the categories mean. Now as David Blei continues to say in the article, this is really only the beginning as while the algorithm can create topics and sort texts it does not really actually know what it is doing. There still needs to be a lot of involvement from the researcher. How many times does the topic model give nonsensical topics or incorrectly identify a text? It is hard to say, and I would assume this depends on how the programmer wrote the algorithm, but like all algorithms, if it is fed garbage it will return garbage.

It really is not surprising at all that the realm of digital humanities would use such a useful tool, but as seen in this article the tool is not the perfect solution. Top modeling algorithms still have to be given some direction both at the begging and at the end, otherwise, the results will likely be useless to the user. Still, despite it needing guidance, the computer can easily analyze the text without knowing what the text actually means which is remarkable. Teaching computers English is hard, so I wonder if this is the best way forward. Is it easier to write a more abstract program as seen here, or is it easier to spend more time making the computer completely understand its job? Both obviously work as shown here, and topic modeling shows the first can be quite easy and reliable, saving researchers lots of time.
